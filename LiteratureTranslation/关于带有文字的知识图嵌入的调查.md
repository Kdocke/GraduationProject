# A Survey on Knowledge Graph <u>Embeddings</u> with <u>Literals</u>: Which model links better Literal-ly? 

```
带文字的知识图嵌入综述：哪个模型在文字上链接得更好？

Embeddings: 嵌入
Literals: 文字
```

Genet Asefa Gesese, Russa Biswas, Mehwish Alam, and Harald Sack
FIZ Karlsruhe - Leibniz <u>Institute</u> for Information <u>Infrastructure</u> & Institute for Applied Informatics and Formal
Description Systems (AIFB), Karlsruhe Institute of Technology, Karlsruhe Germany
E-mails: genet-asefa.gesese@fiz-karlsruhe.de, russa.biswas@fiz-karlsruhe.de, mehwish.alam@fiz-karlsruhe.de, harald.sack@fiz-karlsruhe.de

```
杰内・阿塞法・格塞斯、鲁萨・比斯瓦斯、迈赫威・阿拉姆、哈拉德・萨克
卡尔斯鲁厄 - 莱布尼茨信息基础设施研究所 & 应用信息学和形式研究所
描述系统 (AIFB) ，卡尔斯鲁厄理工学院，德国卡尔斯鲁厄
电子邮件: genet-asefa.gesese@fiz-karlsru.de、russa.biswas@fiz-karlsruhe.de、mehwish.alam@fiz-karlsru.de、harald.sack@fiz-karlsruhe.de

institute: 研究所
Infrastructure: 基础设施
```

**Abstract.** Knowledge Graphs (KGs) are <u>composed</u> of structured information about a particular <u>domain</u> in the form of entities and relations. In addition to the structured information KGs help in <u>facilitating</u> interconnectivity and interoperability between different resources <u>represented</u> in the Linked Data Cloud. KGs have been used in a variety of applications such as entity linking, question answering, recommender systems, etc. However, KG applications suffer from high computational and storage costs. Hence, there arises the necessity for a representation able to map the high dimensional KGs into low dimensional spaces, i.e., embedding space, preserving structural as well as relational information. This paper <u>conducts</u> a survey of KG embedding models which not only consider the structured information contained in the form of entities and relations in a KG but also the unstructured information represented as literals such as text, numerical values, images, etc. Along with a <u>theoretical</u> analysis and comparison of the methods proposed so far for generating KG embeddings with literals, an <u>empirical</u> <u>evaluation</u> of the different methods under identical settings has been performed for the general task of link prediction.

```
摘要.知识图（KGs）由有关特定领域的结构化信息以实体和关系的形式组成。除结构化信息外，KGs 还有助于促进链接数据云中表示的不同资源之间的互连性和互操作性。KGs 已用于各种应用程序中，例如实体链接，问题解答，推荐系统等。但是，KGs 应用程序承受着高昂的计算和存储成本。因此，需要一种能够将高维 KGs 映射到低维空间（即，嵌入空间），保留结构以及相关信息的表示形式。本文对 KG 嵌入模型进行了调查，该模型不仅考虑 KG 中实体和关系形式所包含的结构化信息，而且还考虑以文本，数值，图像等文字形式表示的非结构化信息。除了到目前为止提出的用于生成带有文字的 KG 嵌入的方法的理论分析和比较之外，还针对链接预测的一般任务对相同设置下的不同方法进行了经验评估。

composed: 组成
domain: 领域
facilitating: 促进
represented: 代表
dimensional: 纬度
conducts: 进行
theoretical: 理论的
empirical: 经验
evaluation: 评估
```

**Keywords:** Knowledge Graphs, Knowledge Graph Embeddings, Knowledge Graph Embeddings with Literals, Link Prediction, Survey

```
关键字：知识图、知识图嵌入、具有文字的知识图嵌入、链接预测、调查
```

## 1. Introduction

```
引言
```

  **K**nowledge Graphs (KGs) have become quite <u>crucial</u> for storing structured information. There has been a sudden attention towards using KGs for various applications mainly in the area of artificial intelligence. For instance, in a more general sense, KGs can be used to support decision making process and to improve different machine learning applications such as question answering==[1]==, recommender systems==[2]==, and relation extraction==[3]==. Some of the most popular publicly available general purpose KGs are DBpedia==[4]==,
Freebase==[5]==, Wikidata==[6]==, and YAGO==[7]==. These general purpose KGs often consist of huge amount of facts constructed using billions of entities (represented as nodes) and relations (as edges connecting these nodes).

[1] A.Bordes, S.Chopra and J.Weston, Question Answering with <u>Subgraph</u> Embeddings, in: *Proceedings of the 2014 <u>Conference</u> on Empirical Methods in Natural Language Processing* *(EMNLP)*, Association for Computational Linguistics, Doha, Qatar, 2014, pp. 615–620. doi:10.3115/v1/D14-1067. https://www.aclweb.org/anthology/D14-1067.

[2] F.Zhang, N.J.Yuan, D.Lian, X.Xie and W.-Y. Ma, <u>Collaborative</u> Knowledge Base Embedding for Recommender Systems, in: *Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*, KDD’16, ACM, New York, NY, USA, 2016, pp.353–362. ISBN 978-1-4503-4232-2. doi:10.1145/2939672.2939673.

[3] J.Weston, A.Bordes, O.Yakhnenko and N.Usunier, Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction, in: *Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.*,2013.

[4] J.Lehmann, R.Isele, M.Jakob, A.Jentzsch, D.Kontokostas, P.N.Mendes, S.Hellmann, M.Morsey, P.Van Kleef, S.Auer et al., DBpedia–A Large-scale, Multilingual Knowledge Base Extracted from Wikipedia, *Semantic Web* (2015).

[5] K.Bollacker, C.Evans, P.Paritosh, T.Sturge and J.Taylor, Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge, in: *ACM SIGMOD international conference on Management of data*, 2008.

[6] D.Vrandeciˇc and M.Krötzsch, Wikidata: A Free Collaborative Knowledge Base (2014).

[7] F.Mahdisoltani, J.Biega and F.M.Suchanek, Yago3: A Knowledge Base from Multilingual Wikipedias, in: *CIDR*, 2013.

```
  知识图（KGs）对于存储结构化信息已变得至关重要。突然之间，人们开始关注将 KGs 用于各种应用程序，主要是在人工智能领域。例如，从更一般的意义上讲，KGs 可用于支持决策过程并改善不同的机器学习应用程序，例如问题回答，推荐系统和关系提取。一些最流行的可公开获得的通用 KGs 是 DBpedia，Freebase，Wikidata 和 YAGO。这些通用 KGs 通常由使用数十亿个实体（表示为节点）和关系（作为连接这些节点的边）构造的大量事实组成。
  
[1] A.Bordes, S.Chopra和J.Weston,《带子图嵌入的问答》, 载于:《 2014 年自然语言处理经验方法会议(EMNLP)会议录》, 计算语言学协会, 多哈, 卡塔尔, 2014年, 第615–620页.doi:10.3115/v1/D14-1067. https://www.aclweb.org/anthology/D14-1067.
[2] F.Zhang, N.J.Yuan, D.Lian, X.Xie和W.-Y.Ma, 面向推荐系统的协同知识库嵌入, 载于: 第22届 ACM SIGKDD知识发现和数据挖掘国际会议论文集, KDD’16, ACM, 美国纽约, 2016年, 第353-362页.ISBN 978-1-4503-4232-2.doi:10.1145/2939672.2939673.
[3] J.Weston, A.Bordes, O.Yakhnenko和N.Usunier, 将语言和知识库与关系提取的嵌入模型相连接, 载于: 2013年自然语言处理经验方法会议论文集, 2013年.
[4] J.Lehmann, R.Isele, M.Jakob, A.Jentzsch, D.Kontokostas, P.N.Mendes, S.Hellmann, M.Morsey, P.Van Kleef, S.Auer等人, DBpedia–大型多语言知识库, 摘自 Wikipedia, 语义网(2015).
[5] K.Bollacker, C.Evans, P.Paritosh, T.Sturge和J.Taylor, Freebase: 一个协同创建的人类知识结构图数据库, 载于: ACM SIGMOD 国际数据管理会议上, 2008年.
[6] D.Vrandeciˇc和M.Krötzsch, 维基数据: 免费的协作知识库(2014).
[7] F.Mahdisoltani, J.Biega和F.M.Suchanek, Yago3:多语言维基百科的知识库, CIDR, 2013年.

crucial: 关键的
sense: 意义
extraction: 提取
purpose: 目的

Subgraph: 子图
Conference: 会议
Collaborative: 协同
```

   Although KGs are effective in representing structured data, there exist some issues which hinder their
efficient manipulation such as i) different KGs are usually based on different <u>rigorous</u> symbolic frameworks
and this makes it hard to utilize their data in other applications==[8]== and ii) the fact that a significant number of important graph algorithms needed for the efficient manipulation and analysis of graphs have proven
to be NP-complete==[9]==. In order to address these issues and use a KG more efficiently, it is beneficial to
transform it into a low dimensional vector space while preserving its <u>underlying</u> <u>semantics</u>. To this end, various attempts have been made so far to learn vector representations (embeddings) for KGs. However, most of these approaches, including the current state-of-the-art TransE==[10]==, are structure-based embeddings which do not make use of any literal information i.e., only triples consisting of entities connected via properties are usually considered. This is a major disadvantage because
information encoded in the literals will be left unused when capturing the semantics of a certain entity.

[8] A.Bordes, J.Weston, R.Collobert and Y.Bengio, Learning Structured Embeddings of Knowledge Bases, in: *Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence*, AAAI’11, AAAI Press, 2011, pp.301–306.http://dl.acm.org/citation.cfm?id=2900423.2900470.

[9] M.R.Garey and D.S.Johnson, *Computers and Intractability; A Guide to the Theory of NP-Completeness*, W. H. Freeman & Co., New York, NY, USA, 1990. ISBN 0716710455.

[10] A.Bordes, N.Usunier, A.Garcia-Duran, J.Weston and O.Yakhnenko, Translating Embeddings for Modeling MultiRelational Data, in: *NIPS*, 2013.     

 ```
  尽管 KGs 可以有效地表示结构化数据，但是仍然存在一些妨碍其有效操作的问题，例如 i）不同的 KGs 通常基于不同的严格符号框架，这使得在其他应用程序中难以利用其数据，并且 ii）事实证明，有效操纵和分析图所需的大量重要图算法都是 NP 完全的。为了解决这些问题并更有效地使用 KG，将其转换为低维向量空间同时保留其基本语义是有益的。为此，迄今为止已经进行了各种尝试来学习 KGs 的向量表示（嵌入）。但是，这些方法中的大多数，包括当前最新的 TransE，都是基于结构的嵌入，不使用任何文字信息，即通常只考虑由通过属性连接的实体组成的三元组。这是一个主要缺点，因为在捕获某个实体的语义时，将不使用原义编码的信息。

[8] A.Bordes, J.Weston, R.Collobert和Y.Bengio,《学习结构化的知识嵌入》,载于:《第二十五届AAAI人工智能会议论文集》, AAAI'11, AAAI出版社, 2011年, 第301-306 页.http://dl.acm.org/citation.cfm?id=2900423.2900470
[9] M.R. Garey和D.S. Johnson, 《计算机与难处理》, NP 完全性理论指南, W.H.Freeman＆Co., 美国纽约, 1990年, ISBN 0716710455.
[10] A.Bordes, N.Usunier, A.Garcia-Duran, J.Weston和O.Yakhnenko,《翻译多关系数据建模的嵌入》, NIPS, 2013年.

rigorous: 严格的
underlying: 潜在的
semantics: 语义学
vector: 向量
 ```

   Literals can bring ad van tages to the process of learning KG embeddings in two major ways:

 ```
文字学习者可以通过两种主要方式将广告范式带入学习 KG 嵌入的过程:
 ```

1. *Learning embeddings for novel entities:* Novel entities are entities which are not linked to any other entity in the KG but have literal values associated with them such as their *textual description*. In most existing structure-based embedding models, it is not possible to learn embeddings for such novel entities. However, this can be addressed by utilizing the information represented in literals to learn embeddings. For example, considering the dataset FB15K-20==[11]==, which is a subset of Freebase, the entity ’/m/0gjd61t’ is a novel entity which does not occur in any of the training triples, but it has a description given as follows in the form *<subject, relation, object>*.

   |                                                              |
   | ------------------------------------------------------------ |
   | </m/0gjd61t, http://rdf.freebase.com/ns/common.topic.description, " Vincent Franklin is an English actor best known for his roles in comedy television programmes..."> |

   In order to learn the embedding for this particular entity (i.e., /m/0gjd61t), the model should be enough to make use of the entity’s description. DKRL==[11]== is one of those approaches which provide embeddings for novel entities using their descriptions.

[11] R.Xie, Z.Liu, J.Jia, H.Luan and M. Sun, Representation Learning of Knowledge Graphs with Entity Descriptions, in: *AAAI*, 2016.

```
1. 学习新实体的嵌入：新实体是未与 KG 中的任何其他实体链接但具有与其关联的文字值（例如其文字说明）的实体。在大多数现有的基于结构的嵌入模型中，无法学习此类新颖实体的嵌入。但是，这可以通过利用文字中表示的信息来学习嵌入来解决。例如，考虑数据集 FB15K-20（它是 Freebase 的子集），实体 '/m/ 0gjd61t' 是一个新颖的实体，在任何训练三元组中都不会出现，但它有如下形式的描述<主题，关系，对象>。

</m/0gjd61t, http://rdf.freebase.com/ns/common.topic.description, "文森特・富兰克林是一位英语演员，以在喜剧电视节目中的作用而闻名">

为了了解该特定实体（即 /m/ 0gjd61t）的嵌入，该模型应足以利用该实体的描述。DKRL 是使用其描述为新颖实体提供嵌入的那些方法之一。

[11] R.Xie, Z.Liu, J.Jia, H.Luan和M.Sun, 带有实体描述的知识图的表示学习, 载于:AAAI, 2016.
```

2. Improving the representation of entities in structure based embedding models: Literals play a vital role in improving the representation learning where an entity is required to appear in at least a minimum number of relational triples. For example, taking into consideration only the information provided in a sample KG presented in Figure 1, which is extracted from DBpedia, it is not possible to tell apart the entities dbr:David_Prowse, dbr:Carrie_Fisher, and dbr:Peter_Mayhew from one another. This is the case due to the fact that the only information that is available regarding these entities in this KG is that they all act in the  movie dbr:Return_of_the_Jedi and this is not enough to know which entities are similar to each other and which are not. Therefore, if some KG embedding model is trained using only this KG, it is not possible to get good representations for the entities dbr:David_Prowse, dbr:Carrie_Fisher, and dbr:Peter-Mayhew.

   ![dbr:Return_of_the_Jedi.jpg](<https://raw.githubusercontent.com/Kdocke/MyDocumentImg/master/GraduationProject/LiteratureTranslation/dbr：Return_of_the_Jedi.jpg>)

    Fig.1. A small fraction of triples taken from the KG DBpedia[4].

   However, having the model trained with more triples containing literal values for these entities, as shown in Figure 2, would improve the embeddings for the entities. For instance, looking at the values of the data relation foaf:gender, both dbr:David_Prowse and dbr:Peter_Mayhew are male whereas dbr:Carrie_Fisher is a female. This information alone enables the model to learn a better representation for these entities such that the entities dbr:David_-Prowse and dbr:Peter_Mayhew are more similar to each other than they are to dbr:Carrie_Fisher. The above example indicates that the use of literals along with their respective entities would add more semantics so that similar entities can be represented close to each other in the vector space while those dissimilar are further apart.

```
2.在基于结构的嵌入模型中改善实体的表示：在要求实体至少出现在最小数量的关系三元组中的情况下，文字在改善表示学习方面起着至关重要的作用。例如，仅考虑从 DBpedia 中提取的图1所示样本 KG 中提供的信息，就不可能将实体 dbr:David_Prowse，dbr:Carrie_Fisher 和 dbr:Peter_Mayhew 彼此区分开。之所以如此，是因为以下事实：关于该 KG 中这些实体的唯一可用信息是它们都在电影 dbr:Return_of_the_Jedi 中起作用，而这不足以知道哪些实体彼此相似，哪些不相似。因此，如果仅使用该 KG 训练某些 KG 嵌入模型，则无法获得实体 dbr:David_Prowse，dbr:Carrie_Fisher 和 dbr:Peter-Mayhew 的良好表示。

Fig.1.取自 KG DBpedia 的一小部分三元组

但是，如图 2 所示，使用包含这些实体字面值的更多三元组训练模型，将会改善实体的嵌入。例如，查看数据关系 foaf:gender的值，dbr:David_Prowse 和 dbr:Peter_Mayhew 都是男性，而 dbr:Carrie_Fisher 是女性。仅凭此信息，就可以使模型学习更好地表示这些实体，以使实体dbr: David-Prowse 和 dbr: Peter mayhew 彼此之间的相似性比 dbr: Carrie fisher 更高。上面的示例表明，使用文字及其各自的实体将增加更多的语义，以便相似的实体可以在向量空间中彼此接近地表示，而那些不相似的实体则进一步分开。
```

   Recently, some approaches have been proposed which incorporate the information underlying literals to generate KG embeddings. The types of literals considered in these embedding methods are either text, numeric, images, or multi-modal literals, i.e., a combination of more than one medium of information. These methods use different techniques in order to incorporate the literals into the KG embeddings. However, data typed literals are not addressed in these KG embedding models and surveys that are conducted on KG embeddings. The main challenge with data typed literals, such as date and time, is that they require additional semantics to be represented in KG embeddings.

![dbr:Return_of_the_Jedi.jpg](<https://raw.githubusercontent.com/Kdocke/MyDocumentImg/master/GraduationProject/LiteratureTranslation/dbr：Return_of_the_Jedi%2Babstract.jpg>)

   Fig.2. A small fraction of triples with literals taken from the KG DBpedia[4].

```   
  最近，人们提出了一些利用文本信息生成 KG 嵌入的方法。这些嵌入方法中考虑的文字类型是文本，数字，图像或多模式文字，即多种信息介质的组合。这些方法使用不同的技术，以便将文字合并到 KG 嵌入中。但是，在这些 KG 嵌入模型和对 KG 嵌入进行的调查中，未解决数据类型的文字。数据类型文字（例如日期和时间）的主要挑战在于，它们需要在 KG 嵌入中表示其他语义。
  
Fig.2.三元组的一小部分，其文字取自 KG DBpedia
  
incorporate: 包括
```

   In this survey paper, the focus lies on the analysis of different embedding approaches and highlight their advantages and drawbacks in handling different challenges. Moreover,a review of the different applications used for model evaluation by different KG embedding models has been given with experiments conducted specifically on the link prediction task. The contribution of this paper is summarized as follows:

```
本文重点分析了不同的嵌入方法，突出了它们在处理不同挑战方面的优缺点。此外，还对不同 KG 嵌入模型在模型评估中的应用进行了评述，并针对链接预测任务进行了实验。本文的贡献总结如下：

drawbacks: 缺点
```

1. A detailed analysis of the existing literal enriched KG embedding models and their approaches. In addition, the models are categorized into different classes based on the type of literals used.
2. An evaluation oriented comparison of the existing models on the link prediction task is performed under same experimental settings.
3. The research gaps in the area of KG embeddings in using literals are indicated which can open directions for further research.

```
1. 详细分析了现有文献丰富的 KG 嵌入模型及其方法。 此外，根据所使用的文本类型，模型被分为不同的类。
2. 在相同的实验设置下，对链接预测任务上的现有模型进行了面向评估的比较。
3. 指出了 KG 嵌入在文献使用方面存在的研究空白，为进一步的研究开辟了方向。
```

   The rest of this paper is organized as follows: Section 2 presents a brief overview of related work. In Section 3, the problem formulation including definitions, preliminaries, types of literals and research questions are provided while Section 4 analyses different KG embedding techniques with literals is discussed. Section 5 reviews different tasks used to train or evaluate the embedding models is given. Section 6 discusses the experiment conducted with the existing KG embedding models with literals on the link prediction task. Finally, concluding remarks summarize our findings on KGs with literals and are presented along with future directions in Section 7.

```
  本文的其余部分安排如下：第二部分简要介绍了相关工作。第三部分给出了问题的表述，包括定义、预备知识、文本类型和研究性问题，第四部分分析了不同的 KG 文本嵌入技术。第五部分回顾了训练和评估嵌入模型的不同任务。第六部分讨论了使用现有的 KG 嵌入模型对链接预测任务进行文字编码的实验。最后，结束语总结了我们对带有文字的KGs 的发现，并在第七部分中介绍了未来的方向。
  
preliminaries: 初步的
```

​      

   

